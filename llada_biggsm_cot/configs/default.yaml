# LLaDA CoT Benchmark Configuration
# Copy this file and modify as needed

model:
  model_id: "inclusionAI/LLaDA2.0-mini-CAP"
  torch_dtype: "auto"  # auto, bfloat16, float16, float32
  device_map: "auto"
  trust_remote_code: true

generation:
  gen_length: 512
  steps: 32
  block_length: 32
  temperature: 0.0
  top_p: null
  top_k: null
  eos_early_stop: true

dataset:
  dataset_id: "LightChen2333/BigGSM"
  split: "test"
  n_eval: 60
  seed: 42

# CoT methods to evaluate
methods:
  - "Zero-CoT"
  - "Complex-CoT"
  - "MARP"
  - "Diff-MARP"

# Denoising trace analysis
trace:
  enabled: true
  n_examples: 3
  method: "Diff-MARP"
  threshold: 0.95
  save_heatmaps: true

# Output directories
output_dir: "outputs"
figures_dir: "figures"

# Weights & Biases logging
use_wandb: false
wandb_project: "llada2-bigGSM-cot"
wandb_entity: null  # Your W&B team/username
